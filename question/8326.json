{"type":"question","id":8326,"title":"【深度造假】面對中共下流的抹黑信息戰，您認為可以動用「深假」反擊嗎？有什麼（道德）風險嗎？","uid":8522,"topics":[2013,240,2371],"contents":"中國的十八般武藝，包括潑髒水正在迅速污染輿論，尤其是牆內輿論。<br>\n面對這類惡毒和下流的做法，我們看到許多種做法：<br>\n①變態辣椒組織10.1天安門「你們可以打我了」反向訊息污染。<br>\n②秋實律師親歷香港。<br>\n③深度造假習近平道出真相。<br>\n④各類嚴謹的論證和反駁圖文、視頻的宣傳。<br>\n<br>\n在這之中，我看到了「反向污染」與「深度造假」的潛力。<br>\n<br>\n反向污染：借助官方動用龐大資源炒作的事件/話題，稍加變動，引起相反的作用，製造麻煩，或者大腦升級。<br>\n深度造假：可以通過偉光正形象，說出實情，形成諷刺。或者更加delicate的操作：通過權威形象發布牆內真假難辨的訊息，造成其他混亂或者大腦升級。<br>\n<br>\n方向污染和深度造假有著各種相似和關聯性。污染需要對已有訊息做擬真的修改。而深度造假亦是如此。不過深假相較於傳統的訊息污染，則有更直觀，更大的破壞力。維尼口述中共罪行，或者是維尼號召民眾革命的視頻是十分震撼的。<br>\n<br>\n弊端：<br>\n①所有高雅舉措都有可能被反向利用或者破解。<br>\n②訊息傳播中難以掌控。<br>\n③效果可能失控。<br>\n④面臨道德風險。<br>\n<br>\n試著建議：<br>\n發布深度造假應該從作品本身能表明自己的偽造性質。著重在於傳播諷刺性真相。<br>\n真假難辨的深度造假應該當作核武一樣謹慎使用。<br>\n<br>\n提醒：深度造假不只局限於換臉，還有竊取人聲，以及其他基於該原理的合成技術。<br>\n<br>\n深度造假（Deepfake）的維基詞條<br>\n<blockquote>Deepfake<br>\n<br>\n<ul><br>\n<li><a href=\"https://en.m.wikipedia.org/wiki/Special:MobileLanguages/Deepfake\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">Read in another language</a></li><br>\n<li><a href=\"https://en.m.wikipedia.org/w/index.phptitle=Special:UserLogin&amp;returnto=Deepfake\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">Watch</a></li><br>\n<li><a href=\"https://en.m.wikipedia.org/w/index.phptitle=Deepfake&amp;action=edit&amp;section=0\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">Edit</a></li><br>\n</ul><br>\n<br>\n<a href=\"https://en.m.wikipedia.org/wiki/File:Deepfake_example.gif\" rel=\"nofollow noreferrer noopener\" target=\"_blank\"><a href=\"https://upload.wikimedia.org/wikipedia/en/thumb/7/71/Deepfake_example.gif/280px-Deepfake_example.gif\" rel=\"nofollow noreferrer noopener\" target=\"_blank\"><img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/7/71/Deepfake_example.gif/280px-Deepfake_example.gif\" alt=\"https://upload.wikimedia.org/wikipedia/en/thumb/7/71/Deepfake_example.gif/280px-Deepfake_example.gif\" style=\"max-width:100%\"></a></a><br>\nAn example of deepfake technology – actress&nbsp;<a href=\"https://en.m.wikipedia.org/wiki/Amy_Adams\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">Amy&nbsp;Adams</a>&nbsp;in the original (left) is modified to have the face of actor&nbsp;<a href=\"https://en.m.wikipedia.org/wiki/Nicolas_Cage\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">Nicolas&nbsp;Cage</a>&nbsp;(right).<br>\n<b>Deepfake</b>&nbsp;(a&nbsp;<a href=\"https://en.m.wikipedia.org/wiki/Portmanteau\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">portmanteau</a>&nbsp;of &quot;<a href=\"https://en.m.wikipedia.org/wiki/Deep_learning\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">deep learning</a>&quot; and &quot;fake&quot;<a href=\"https://en.m.wikipedia.org/wiki/Deepfake#cite_note-FoxNews2018-1\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">[1]</a>) is a technique for&nbsp;<a href=\"https://en.m.wikipedia.org/wiki/Human_image_synthesis\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">human image synthesis</a>&nbsp;based on&nbsp;<a href=\"https://en.m.wikipedia.org/wiki/Artificial_intelligence\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">artificial intelligence</a>. It is used to combine and&nbsp;<a href=\"https://en.m.wikipedia.org/wiki/Superimposition\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">superimpose</a>&nbsp;existing images and videos onto source images or videos using a&nbsp;<a href=\"https://en.m.wikipedia.org/wiki/Machine_learning\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">machine learning</a>&nbsp;technique known as&nbsp;<a href=\"https://en.m.wikipedia.org/wiki/Generative_adversarial_network\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">generative adversarial network</a>.<a href=\"https://en.m.wikipedia.org/wiki/Deepfake#cite_note-Schwartz-2\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">[2]</a>&nbsp;Because of these capabilities, deepfakes have been used to create fake&nbsp;<a href=\"https://en.m.wikipedia.org/wiki/Celebrity_sex_tape\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">celebrity pornographic videos</a>&nbsp;or&nbsp;<a href=\"https://en.m.wikipedia.org/wiki/Revenge_porn\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">revenge porn</a>.<a href=\"https://en.m.wikipedia.org/wiki/Deepfake#cite_note-HighSnobiety2018-3\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">[3]</a>&nbsp;Deepfakes can also be used to create&nbsp;<a href=\"https://en.m.wikipedia.org/wiki/Fake_news\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">fake news</a>&nbsp;and malicious&nbsp;<a href=\"https://en.m.wikipedia.org/wiki/Hoax\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">hoaxes</a>.<a href=\"https://en.m.wikipedia.org/wiki/Deepfake#cite_note-4\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">[4]</a><a href=\"https://en.m.wikipedia.org/wiki/Deepfake#cite_note-5\" rel=\"nofollow noreferrer noopener\" target=\"_blank\">[5]<br>\n</a><br>\nDeepfake <br>\n用另一種語言閱讀 <br>\n看 <br>\n編輯 <br>\n深度技術的一個例子 - 原版（左）中的女演員艾米·亞當斯被修改為具有演員尼古拉斯·凱奇（右）的面孔。<br>\n Deepfake（一種“深度學習”和“假”[1]）是一種基於人工智能的人體圖像合成技術。它用於使用稱為生成對抗網絡的機器學習技術將現有圖像和視頻組合併疊加到源圖像或視頻上。[2]由於這些功能，深度偽造被用來製作虛假的名人色情視頻或複仇色情。[3] Deepfakes也可用於製造假新聞和惡意惡作劇。[4] [5]<br>\n</blockquote><br>\n大家怎麼看？","date":"2019-09-10","agreeCount":4,"discussionCount":0}