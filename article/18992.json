{"type":"article","id":18992,"title":"【羊城教室】为什么线性代数如此重要？以及其在人工智能上的应用。（原创）","uid":2296,"topics":[1646,9068,9069,240],"contents":"<blockquote>21世纪的文盲将不会是那些不会读写的人，而是那些不会学习，学习和重新学习的人。<br>\n-&nbsp;阿尔文·托夫勒</blockquote><br>\n<br>\n我们常常在大学里学习的线性代数主要涉及的内容是矩阵的变化及其一些性质。<br>\n<a href=\"https://i.imgur.com/p0MmcTs.png\" rel=\"nofollow noreferrer noopener\" target=\"_blank\"><img src=\"https://i.imgur.com/p0MmcTs.png\" alt=\"https://i.imgur.com/p0MmcTs.png\" style=\"max-width:100%\"></a><br>\n矩阵的计算看起来就让人头大？（尤其是在你没有MATLAB的情况下）但是让我们问两个问题。它们都是从哪儿来的？为什么需要这些运算？<br>\n<br>\n让我们做个简单的练习。线性代数是计算数学的「主要基础」。<br>\n<br>\n窝举个简单的例子来说明。假设我们有一根两端固定的极细金属棒，其温度恒等于零。我们开始使用分布式热源对棒进行加热，该热源在点 x 的附近，每单位长度每秒产生 q (x) 焦耳热量。温度 t = t (x) 公式该怎么建立？先粗略建模：热量平衡后，设点 x 的分段为 [x-h, x + h]，来自热源的热流入应等于分段两端的热通量之和。如果 h 足够小，那么热通量可以看作常量（包含 h），该等式可以写成如下形式：<br>\n<br>\n<a href=\"https://i.imgur.com/zrurivc.png\" rel=\"nofollow noreferrer noopener\" target=\"_blank\"><img src=\"https://i.imgur.com/zrurivc.png\" alt=\"https://i.imgur.com/zrurivc.png\" style=\"max-width:100%\"></a><br>\n<br>\n其中 Q_x-h 是通过左边界的热通量，Q_x + h 是通过右边界的热通量。根据傅立叶定律，热通量与温度差成正比（毕竟，你刚跳进水里时感觉最冷）。因此：<br>\n<br>\n<a href=\"https://i.imgur.com/14BdzxU.png\" rel=\"nofollow noreferrer noopener\" target=\"_blank\"><img src=\"https://i.imgur.com/14BdzxU.png\" alt=\"https://i.imgur.com/14BdzxU.png\" style=\"max-width:100%\"></a><br>\n<br>\n<br>\n令 h = 1 /N。假设 xi = i · h，其中 i =0, 1, 2, …, N，它们被称为网格。变量 ti = t (xi) 将满足方程式：<br>\n<br>\n<a href=\"https://i.imgur.com/1wAhl4f.png\" rel=\"nofollow noreferrer noopener\" target=\"_blank\"><img src=\"https://i.imgur.com/1wAhl4f.png\" alt=\"https://i.imgur.com/1wAhl4f.png\" style=\"max-width:100%\"></a><br>\n<br>\n基于边界条件且 qi = q (xi)，得到线性方程组：<br>\n<br>\n<a href=\"https://i.imgur.com/MqJZA1P.png\" rel=\"nofollow noreferrer noopener\" target=\"_blank\"><img src=\"https://i.imgur.com/MqJZA1P.png\" alt=\"https://i.imgur.com/MqJZA1P.png\" style=\"max-width:100%\"></a><br>\n<br>\n具体来说，这个系统可以通过扫描法「正面」解决，但是在实际模型中，系统变得更加复杂。线性代数正好发挥了作用：<b>用 A · y = b 的简短形式描述系统（这是矩阵乘法的由来！）；</b>了解是否有解决方案，以及解决方案是否唯一；（在本例中）使用简单公式 y = A-1 b 来建模，将 A 看做一个数字；（引入计算数学）建立用于求解线性方程组的有效数值方法。这只是从数学建模的角度看线性代数，还有量子力学、统计学等多个角度。<br>\n<br>\n再以著名问题为例，即某网站（或整个互联网）的「网页引用排名」问题。假设有 N 个页面，每页可能包含到其他页面的链接。我们的任务是确定哪些页面最重要。如何准确地衡量「重要性」是任务的一部分。我们将以非负数（权重）来定量表示。先假设：此页面的链接越多，其权重就越大。这种方法有个缺点：我们没有考虑链接页面的权重。一个链接权重越大，其意义也越大，这是合乎逻辑的。考虑到这些因素，我们选择以下模型：<br>\n<a href=\"https://i.imgur.com/qurb3n1.png\" rel=\"nofollow noreferrer noopener\" target=\"_blank\"><img src=\"https://i.imgur.com/qurb3n1.png\" alt=\"https://i.imgur.com/qurb3n1.png\" style=\"max-width:100%\"></a><br>\n其中 a_ij 是第 i 页到第 j 页的链接数，除以第 j 页的链接总数。该公式可以理解为：第 i 页的权重等于第 j 页的权重与从第 j 页到第 i 页的链接之比的乘积之和。<br>\n<br>\n因此，我们将问题简化为线性方程组。因此，线性代数是一套非常通用的思想和工具，可以应用于各个领域。<br>\n<br>\n<br>\n<b>线性代数在人工智能的应用</b><br>\n<br>\n例如使用线性代数来找到点与点之间的最短路径。以下是你所需要掌握的知识列表：标量、向量、张量：求模（大小）、向量夹角（点积或内积）、一个向量在另一向量上的投影以及依据自定义的轴向量对向量的描述和表示矩阵：矩阵可以将向量的描述从一组基（一组坐标轴）转换为另一组基。<br>\n<br>\n例如，找出如何将映射应用到图像上并处理图像。矩阵中的长度平方采样、奇异值分解、低秩逼近是数据处理中广泛采用的几种方法。SVD 通常用于主成分分析（PCA）中，而主成分分析又被广泛用于特征提取以及了解特征或属性之间的关系对于结果的重要性上。<br>\n<br>\n<b>线性代数在机器学习中的应用</b><br>\n<br>\n<ol><li><b>实例数据集和数据文件</b>：例如在机器学习中，将模型拟合到一组由数字组成的类似表格的数据集上，其中每一行代表一个观测结果，每一列代表该观测值的特征。这些数据实际上是一个矩阵：是线性代数中的一种关键的数据结构。</li><li><b>图像和照片</b>：你处理的每个图像本身就是一个表结构，对于黑白图像，每个单元格中有一个宽度和高度以及一个像素值，而彩色图像每个单元格中有三个像素值。照片是线性代数矩阵的另一个例子。</li><li><b>线性回归</b>：线性回归是统计学中描述变量之间关系的一种旧方法。在机器学习中，它通常用于预测简单回归问题中的数值。</li><li><b>深度学习</b>：线性代数是描述深度学习方法的核心，通过矩阵表示法来实现深度学习方法，例如谷歌的 TensorFlow Python 库，其名称中就有「tensor」一词。</li></ol><br>\n<br>\n<b>下面是窝在学习线性代数时总结的技巧：</b><br>\n<ul><li>在解决有趣的问题时，是最容易理解线性代数思想和方法的，趣味问题有助于理解抽象概念；</li><li>要经常在大脑中构造线性代数的映射，做矩阵计算的时候，尝试用想象力将矩阵“活起来”；</li><li>记得要与其他人（朋友，或论坛）一起学习；</li><li>注意多读一些教科书外的拓展内容，并且将你学过的线性代数和其生活中的应用联系起来，这可以促使你深度思考。</li></ul>","date":"2020-05-17","agreeCount":45,"discussionCount":0}