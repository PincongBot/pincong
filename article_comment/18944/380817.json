{"type":"article_comment","id":380817,"parentType":"article","parentId":18944,"uid":49656,"contents":"我想我可能可以幫忙寫一下近幾年 deep learning in NLP 的東東.<br>\n<br>\n可能夠科普一下, 讓大家快速了解一下, 不用花太多時間看一大堆文章.<br>\n<br>\n建立一下像openreview but for public science.&nbsp;<br>\n<br>\nTopics could be the follows:<br>\n- seq2seq, encoder-decoder<br>\n- how attention helps neural machine translation<br>\n-- translation alignment and attention<br>\n- self-attention, unsupervised pretraining","date":"2020-05-18","agreeCount":0,"discussionCount":0}