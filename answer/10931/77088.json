{"type":"answer","id":77088,"parentType":"question","parentId":10931,"uid":17767,"contents":"技术上来猜测，之前有稍微了解过一点以大数据为基础的模型建立流程，有可能的确不是人为程序故意写的，而是苹果的样本数据量不够“庞大”，不能涵盖所有用户，或者特征项不是“足够多”，导致建立的模型在做真实用户题目时，出现了这种结果欠拟合现象，部分用户预测不准。<br>\n<br>\n比如就像楼上说到的，特征项如果只记录了本人的情况，没有考虑配偶经济状况，家务分配情况，子女数量等等等等各种复杂条件；<br>\n还有的可能就是本身数据集里，相同特征条件下大部分女性用户的信用很差，而那位女士只是幸存者偏差。","date":"2019-11-13","agreeCount":2,"discussionCount":0}